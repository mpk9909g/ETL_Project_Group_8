{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "This is the jupyter notebook file for the ETL project by group 8. Our group members are Matt Keeley, Jim Hurley, and Feipeng Yang. In this project, we extracted real estate data and air quality data from two different sources, transformed the data to be compatible with each other and with pgAdmin, and loaded the data into a SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pandas and object relational mapper modules\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract\n",
    "In this section, data from the following CSV files are extracted using pandas and loaded into dataframes. \n",
    "1. File containing air quality data: aqi_yearly_1980_to_2021.csv https://www.kaggle.com/threnjen/40-years-of-air-quality-index-from-the-epa-yearly\n",
    "2. File containing real estate data from realter.com: RDC_Inventory_Core_Metrics_County.csv https://econdata.s3-us-west-2.amazonaws.com/Reports/Core/RDC_Inventory_Core_Metrics_County.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract air quality data from .csv file into dataframe\n",
    "air_quality_file = \"Resources/aqi_yearly_1980_to_2021.csv\"\n",
    "air_quality_file_df = pd.read_csv(air_quality_file)\n",
    "air_quality_file_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract real estate data from .csv file into dataframe\n",
    "rdc_listings_file = \"Resources/RDC_Inventory_Core_Metrics_County.csv\"\n",
    "rdc_listings_file_df = pd.read_csv(rdc_listings_file)\n",
    "rdc_listings_file_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "In this section, the real estate data and air quality data extracted from CSV files are transformed. The following changes are made to make the files compatible with each other and with pgAdmin database. \n",
    "\n",
    "### Transformation: air quality data\n",
    "The following changes are made for air quality data transformation:\n",
    "1. Select columns of interest.\n",
    "2. Filter the data to only include data for 2021.\n",
    "3. Change the column names to lower cases to be compatible with SQL database.\n",
    "4. Rename the index to \"id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that will be transformed from the air_quality_file_df dataframe\n",
    "air_quality_file_cols = [\"State\", \"County\", \"Year\",\"Median AQI\"]\n",
    "\n",
    "# load the data from the selected columns into a new dataframe\n",
    "air_quality_file_transformed_df= air_quality_file_df[air_quality_file_cols].copy()\n",
    "air_quality_file_transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe that only contain the data for the year 2021\n",
    "air_quality_filtered_df = air_quality_file_transformed_df.loc[air_quality_file_transformed_df[\"Year\"] == 2021, :]\n",
    "air_quality_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columnsto lower cases\n",
    "air_quality_df = air_quality_filtered_df.rename(columns={\"State\": \"state\",\n",
    "                                                         \"County\":\"county\",\n",
    "                                                         \"Year\": \"year\",\n",
    "                                                         \"Median AQI\": \"median_aqi\"})\n",
    "air_quality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the index as \"id\", this is the transformed air quality dataframe that is ready to load into database\n",
    "air_quality_df.index.name = 'id'\n",
    "air_quality_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation: real estate data\n",
    "The following changes are made for real estate data transformation:\n",
    "1. Select columns of interest.\n",
    "2. Split the column \"county_name\" into two columns: \"County\" and \"State\" so that it can match the columns in air quality dataframe.\n",
    "3. Change the \"State\" column from state code to full state name by loading and merging a .csv file containing US state abbreviations: state_abbreviation.csv https://worldpopulationreview.com/states/state-abbreviations\n",
    "4. Change the column names to lower cases to be compatible with SQL database.\n",
    "5. Rename the index to \"id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that will be transformed from the rdc_listings_file_df dataframe\n",
    "rdc_listings_file_cols = [\"month_date_yyyymm\", \"county_name\", \"total_listing_count\", \"average_listing_price\", \n",
    "                          \"median_listing_price\", \"active_listing_count\", \"median_days_on_market\"]\n",
    "listings_file_transformed_df= rdc_listings_file_df[rdc_listings_file_cols].copy()\n",
    "listings_file_transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the column \"county_name\" to two columns: \"County\" and \"State\"\n",
    "listings_file_transformed_df[['County', 'State']] = listings_file_transformed_df['county_name'].str.split(', ', 1, expand=True)\n",
    "listings_file_transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-orginize the dataframe by selecting columns and assign to a new dataframe\n",
    "df = listings_file_transformed_df[[\"month_date_yyyymm\", \"County\", \"State\",\"total_listing_count\", \"average_listing_price\", \n",
    "                                   \"median_listing_price\", \"active_listing_count\", \"median_days_on_market\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the strings in the \"State\" column to upper cases\n",
    "df[\"State\"] = df[\"State\"].str.upper()\n",
    "\n",
    "# change the strings in the \"County\" column to title (upper case for the first letter in each word)\n",
    "df[\"County\"] = df[\"County\"].str.title()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the \"State\" column in the air quality dataframe (air_quality_df) is shown as full name and the \"State\" column in the real estate dataframe (df) is shown as state code, we decided to load in a .csv file that contain the state abbreviation information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in state name - state abbreviation conversion table\n",
    "state_abbreviation_file = \"Resources/state_abbreviation.csv\"\n",
    "state_abbreviation_file_df = pd.read_csv(state_abbreviation_file)\n",
    "state_abbreviation_file_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the real estate dataframe (df) with state abbreviation dataframe\n",
    "merge_df = pd.merge(df, state_abbreviation_file_df, left_on=\"State\", right_on=\"Code\")\n",
    "\n",
    "# change the data type for \"average_listing_price\" from \"float64\" to \"int64\", and assign to a new column\n",
    "merge_df['Average_price']=merge_df['average_listing_price'].astype('int64')\n",
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that will be used from the merged dataframe\n",
    "listings_df = merge_df[[\"County\", \"State_x\",\"State_y\",\"total_listing_count\", \"Average_price\", \n",
    "                        \"median_listing_price\", \"active_listing_count\", \"median_days_on_market\"]]\n",
    "\n",
    "# rename the columns to lower cases\n",
    "listings_df = listings_df.rename(columns={\"month_date_yyyymm\": \"current_month\",\n",
    "                                          \"County\":\"county\",\n",
    "                                          \"State_x\":\"state_initial\",\n",
    "                                          \"State_y\": \"state\",\n",
    "                                          \"Average_price\": \"average_price\"})\n",
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the index as \"id\", this is the transformed real estate listing dataframe that is ready to load into database\n",
    "listings_df.index.name = 'id'\n",
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load\n",
    "This section loads the two dataframs: listings and air quality into SQL database. \n",
    "\n",
    "### Create database connection\n",
    "Before running the following code, a database needs to be initialized on the local server. Here are the steps to create an empty database in pgAdmin:\n",
    "1. Create a database called \"realestate_db\".\n",
    "2. Create two tables \"listings\" and \"air_quality\" in the realestate_db database using the following query code:\n",
    "\n",
    "        CREATE TABLE listings (\n",
    "          id INT PRIMARY KEY,\n",
    "          county TEXT,\n",
    "          state_initial TEXT,\n",
    "          state TEXT,\n",
    "          total_listing_count INT,\n",
    "          average_price INT,\n",
    "          median_listing_price INT,\n",
    "          active_listing_count INT,\n",
    "          median_days_on_market INT\n",
    "        );\n",
    "\n",
    "\n",
    "\n",
    "        CREATE TABLE air_quality (\n",
    "          id INT PRIMARY KEY,\n",
    "          state TEXT,\n",
    "          county TEXT,\n",
    "          year INT,\n",
    "          median_aqi INT\n",
    "        );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create our database engine\n",
    "connection_string = \"postgres:bootcamp@localhost:5432/realestate_db\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the tables in the \"realestate_db\" database\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataFrames into database\n",
    "Transformed dataframes are loaded into SQL database using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load csv converted air quality DataFrame into database\n",
    "air_quality_df.to_sql(name='air_quality', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load csv converted listing DataFrame into database\n",
    "listings_df.to_sql(name='listings', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm data load\n",
    "Loading of the data into SQL database was confirmed by quarying the \"listings\" and \"air_quality\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm data has been added by querying the \"listings\" table\n",
    "pd.read_sql_query('select * from listings', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm data has been added by querying the \"air_quality\" table\n",
    "pd.read_sql_query('select * from air_quality', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
